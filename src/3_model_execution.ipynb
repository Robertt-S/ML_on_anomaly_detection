{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from hiclass import LocalClassifierPerNode, LocalClassifierPerLevel, LocalClassifierPerParentNode\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, recall_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de utilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train, X_test, y_train, y_test, scores = False, hierarchical = False):\n",
    "  model.fit(X_train, y_train)\n",
    "  y_predicted = model.predict(X_test).astype(int)\n",
    "\n",
    "  if scores:\n",
    "    if hierarchical:\n",
    "      test_accuracy_binary = accuracy_score(y_test[\"Label\"], y_predicted[:, 0])\n",
    "      test_accuracy_multiclass = accuracy_score(y_test[\"attack_cat\"], y_predicted[:, 1])\n",
    "      test_balanced_accuracy_binary = balanced_accuracy_score(y_test[\"Label\"], y_predicted[:, 0])\n",
    "      test_balanced_accuracy_multiclass = balanced_accuracy_score(y_test[\"attack_cat\"], y_predicted[:, 1])\n",
    "      test_precision_binary = precision_score(y_test[\"Label\"], y_predicted[:, 0], average = None, zero_division = np.nan)\n",
    "      test_precision_multiclass = precision_score(y_test[\"attack_cat\"], y_predicted[:, 1], average = None, zero_division = np.nan)\n",
    "      test_recall_binary = recall_score(y_test[\"Label\"], y_predicted[:, 0], average = None, zero_division = np.nan)\n",
    "      test_recall_multiclass = recall_score(y_test[\"attack_cat\"], y_predicted[:, 1], average = None, zero_division = np.nan)\n",
    "      test_f1_binary = f1_score(y_test[\"Label\"], y_predicted[:, 0], average = None, zero_division = np.nan)\n",
    "      test_f1_multiclass = f1_score(y_test[\"attack_cat\"], y_predicted[:, 1], average = None, zero_division = np.nan)\n",
    "\n",
    "      return [{\"Acurácia no Teste Binário\": test_accuracy_binary,\n",
    "                \"Acurácia no Teste Multiclasse\": test_accuracy_multiclass,\n",
    "                \"Acurácia Balanceada no Teste Binário\": test_balanced_accuracy_binary,\n",
    "                \"Acurácia Balanceada no Teste Multiclasse\": test_balanced_accuracy_multiclass,\n",
    "                \"Precisão Binário\": test_precision_binary,\n",
    "                \"Precisão Multiclasse\": test_precision_multiclass,\n",
    "                \"Recall Binário\": test_recall_binary,\n",
    "                \"Recall Multiclasse\": test_recall_multiclass,\n",
    "                \"F1 Binário\": test_f1_binary,\n",
    "                \"F1 Multiclasse\": test_f1_multiclass},\n",
    "                confusion_matrix(y_test[\"Label\"], y_predicted[:, 0]),\n",
    "                confusion_matrix(y_test[\"attack_cat\"], y_predicted[:, 1])]\n",
    "    else:\n",
    "      test_accuracy = accuracy_score(y_test, y_predicted)\n",
    "      test_balanced_accuracy = balanced_accuracy_score(y_test, y_predicted)\n",
    "      test_precision = precision_score(y_test, y_predicted, average = None, zero_division = np.nan)\n",
    "      test_recall = recall_score(y_test, y_predicted, average = None)\n",
    "      test_f1 = f1_score(y_test, y_predicted, average = None)\n",
    "    \n",
    "      return [pd.DataFrame({\"Acurácia no Teste\": test_accuracy, \n",
    "                            \"Acurácia Balanceada no Teste\": test_balanced_accuracy,\n",
    "                            \"Precisão\": test_precision,\n",
    "                            \"Recall\": test_recall,\n",
    "                            \"F1\": test_f1}), \n",
    "                            confusion_matrix(y_test, y_predicted)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega-se os dados pré-processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pkl.load(open(\"../data/files/Normalized_Data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = [\"attack_cat\", \"Label\"])\n",
    "y = df[[\"attack_cat\", \"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y[[\"Label\", \"attack_cat\"]], test_size = 0.2, stratify = y, random_state = 42)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação da base em K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = KFold(n_splits = 5, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção das características mais importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_binary = X_train[[\"dstip\", \"ct_state_ttl\", \"sttl\", \"srcip\", \"sbytes\", \"smeansz\", \"dmeansz\", \"Sload\"]]\n",
    "X_test_binary = X_test[[\"dstip\", \"ct_state_ttl\", \"sttl\", \"srcip\", \"sbytes\", \"smeansz\", \"dmeansz\", \"Sload\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos Adaptive Boosting, Random Forest, Bagging, Extreme Gradient Boosting e Multilayer Perceptron | Classificação binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier(random_state = 42, algorithm = \"SAMME\", n_estimators = 400, learning_rate = 1.5)\n",
    "random_forest = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = -1)\n",
    "bagging = BaggingClassifier(random_state = 42, n_estimators = 100, max_features = 1, max_samples = 0.3, n_jobs = -1)\n",
    "mlp = MLPClassifier(random_state = 42, activation = \"tanh\", hidden_layer_sizes = (100, 100, 100))\n",
    "xgboost = xgb.XGBClassifier(random_state = 42, n_estimators = 400, max_depth = 5, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost\n",
      "Acurácia no treino 0.9898077141691523 \n",
      "Acurácia no teste: 0.989616284814973 \n",
      "Acurácia balanceada no teste: 0.9810401500313333\n",
      "\n",
      "Random Forest\n",
      "Acurácia no treino 0.9954498636090957 \n",
      "Acurácia no teste: 0.9925965587088367 \n",
      "Acurácia balanceada no teste: 0.9812687681136072\n",
      "\n",
      "Bagging\n",
      "Acurácia no treino 0.9865562809942978 \n",
      "Acurácia no teste: 0.9862777481412658 \n",
      "Acurácia balanceada no teste: 0.9913534674646067\n",
      "\n",
      "MLP\n",
      "Acurácia no treino 0.9893485667267217 \n",
      "Acurácia no teste: 0.9891458188568267 \n",
      "Acurácia balanceada no teste: 0.9802983852649803\n",
      "\n",
      "XGBoost\n",
      "Acurácia no treino 0.9922550241704465 \n",
      "Acurácia no teste: 0.9918583799042139 \n",
      "Acurácia balanceada no teste: 0.9826362914765465\n",
      "\n",
      "Stacking\n",
      "Acurácia no treino 0.9943352130655744 \n",
      "Acurácia no teste: 0.9925296304972175 \n",
      "Acurácia balanceada no teste: 0.9809576240479746\n"
     ]
    }
   ],
   "source": [
    "print(\"Ada Boost\")\n",
    "run_model(ada_boost, X_train_binary, X_test_binary, y_train[\"Label\"], y_test[\"Label\"])\n",
    "print(\"\\nRandom Forest\")\n",
    "run_model(random_forest, X_train_binary, X_test_binary, y_train[\"Label\"], y_test[\"Label\"])\n",
    "print(\"\\nBagging\")\n",
    "run_model(bagging, X_train_binary, X_test_binary, y_train[\"Label\"], y_test[\"Label\"])\n",
    "print(\"\\nMLP\")\n",
    "run_model(mlp, X_train_binary, X_test_binary, y_train[\"Label\"], y_test[\"Label\"])\n",
    "print(\"\\nXGBoost\")\n",
    "run_model(xgboost, X_train_binary, X_test_binary, y_train[\"Label\"], y_test[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva-se os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(ada_boost, open(\"../data/utilities/models/ada_boost_binary.pkl\", \"wb\"))\n",
    "pkl.dump(random_forest, open(\"../data/utilities/models/random_forest_binary.pkl\", \"wb\"))\n",
    "pkl.dump(bagging, open(\"../data/utilities/models/bagging_binary.pkl\", \"wb\"))\n",
    "pkl.dump(mlp, open(\"../data/utilities/models/mlp_binary.pkl\", \"wb\"))\n",
    "pkl.dump(xgboost, open(\"../data/utilities/models/xgboost_binary.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos Adaptive Boosting, Random Forest, Bagging, Extreme Gradient Boosting e Multilayer Perceptron | Classificação multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier(random_state = 42, algorithm = \"SAMME\", n_estimators = 400, learning_rate = 1.5)\n",
    "random_forest = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = -1)\n",
    "bagging = BaggingClassifier(random_state = 42, n_estimators = 100, max_features = 1, max_samples = 0.3, n_jobs = -1)\n",
    "mlp = MLPClassifier(random_state = 42, activation = \"tanh\", hidden_layer_sizes = (100, 100, 100))\n",
    "xgboost = xgb.XGBClassifier(random_state = 42, n_estimators = 400, max_depth = 5, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ada Boost\")\n",
    "run_model(ada_boost, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"])\n",
    "print(\"\\nRandom Forest\")\n",
    "run_model(random_forest, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"])\n",
    "print(\"\\nBagging\")\n",
    "run_model(bagging, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"])\n",
    "print(\"\\nMLP\")\n",
    "run_model(mlp, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"])\n",
    "print(\"\\nXGBoost\")\n",
    "run_model(xgboost, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva-se os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(ada_boost, open(\"../data/utilities/models/ada_boost_multiclass.pkl\", \"wb\"))\n",
    "pkl.dump(random_forest, open(\"../data/utilities/models/random_forest_multiclass.pkl\", \"wb\"))\n",
    "pkl.dump(bagging, open(\"../data/utilities/models/bagging_multiclass.pkl\", \"wb\"))\n",
    "pkl.dump(mlp, open(\"../data/utilities/models/mlp_multiclass.pkl\", \"wb\"))\n",
    "pkl.dump(xgboost, open(\"../data/utilities/models/xgboost_multiclass.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos: Classificador Local por Nó, Classificador Local por Nó Pai e Classificador Local por Nível | Classificação Hierárquica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_classifier_per_node_base_estimator = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = 2)\n",
    "local_classifier_per_parent_node_base_estimator = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = 2)\n",
    "local_classifier_per_level_base_estimator = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = 2)\n",
    "\n",
    "local_classifier_per_node = LocalClassifierPerNode(local_classifier_per_node_base_estimator)\n",
    "local_classifier_per_parent_node = LocalClassifierPerParentNode(local_classifier_per_parent_node_base_estimator)\n",
    "local_classifier_per_level = LocalClassifierPerLevel(local_classifier_per_level_base_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Classifier Per Node\n",
      "\n",
      "Local Classifier Per Parent Node\n",
      "\n",
      "Local Classifier Per Level\n"
     ]
    }
   ],
   "source": [
    "print(\"Local Classifier Per Node\")\n",
    "run_model(local_classifier_per_node, X_train, X_test, y_train[[\"Label\", \"attack_cat\"]], y_test[[\"Label\", \"attack_cat\"]])\n",
    "print(\"\\nLocal Classifier Per Parent Node\")\n",
    "run_model(local_classifier_per_parent_node, X_train, X_test, y_train[[\"Label\", \"attack_cat\"]], y_test[[\"Label\", \"attack_cat\"]])\n",
    "print(\"\\nLocal Classifier Per Level\")\n",
    "run_model(local_classifier_per_level, X_train, X_test, y_train[[\"Label\", \"attack_cat\"]], y_test[[\"Label\", \"attack_cat\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva-se os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(local_classifier_per_node, open(\"../data/utilities/models/local_classifier_per_node.pkl\", \"wb\"))\n",
    "pkl.dump(local_classifier_per_parent_node, open(\"../data/utilities/models/local_classifier_per_parent_node.pkl\", \"wb\"))\n",
    "pkl.dump(local_classifier_per_level, open(\"../data/utilities/models/local_classifier_per_level.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos Adaptive Boosting, Random Forest, Bagging, Extreme Gradient Boosting e Multilayer Perceptron em validação cruzada | Classificação binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier(random_state = 42, algorithm = \"SAMME\", n_estimators = 400, learning_rate = 1.5)\n",
    "random_forest = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = -1)\n",
    "bagging = BaggingClassifier(random_state = 42, n_estimators = 100, max_features = 1, max_samples = 0.3, n_jobs = -1)\n",
    "mlp = MLPClassifier(random_state = 42, activation = \"tanh\", hidden_layer_sizes = (100, 100, 100))\n",
    "xgboost = xgb.XGBClassifier(random_state = 42, n_estimators = 400, max_depth = 5, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_scores_binary = []; random_forest_scores_binary = []; bagging_scores_binary = []; mlp_scores_binary = []; xgboost_scores_binary = []\n",
    "\n",
    "\n",
    "for i, j in k_folds.split(X):\n",
    "  X_train = X.iloc[i][[\"dstip\", \"ct_state_ttl\", \"sttl\", \"srcip\", \"sbytes\", \"smeansz\", \"dmeansz\", \"Sload\"]]\n",
    "  X_test = X.iloc[j][[\"dstip\", \"ct_state_ttl\", \"sttl\", \"srcip\", \"sbytes\", \"smeansz\", \"dmeansz\", \"Sload\"]]\n",
    "  y_train, y_test = y.iloc[i], y.iloc[j]\n",
    "\n",
    "\n",
    "  print(\"AdaBoost\")\n",
    "  model_scores = run_model(ada_boost, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], scores = True)\n",
    "  ada_boost_scores_binary.append(model_scores)\n",
    "  print(\"\\nRandom Forest\")\n",
    "  model_scores = run_model(random_forest, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], scores = True)\n",
    "  random_forest_scores_binary.append(model_scores)\n",
    "  print(\"\\nBagging\")\n",
    "  model_scores = run_model(bagging, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], scores = True)\n",
    "  bagging_scores_binary.append(model_scores)\n",
    "  print(\"\\nMLP\")\n",
    "  model_scores = run_model(mlp, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], scores = True)\n",
    "  mlp_scores_binary.append(model_scores)\n",
    "  print(\"\\nXGBoost\")\n",
    "  model_scores = run_model(xgboost, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], scores = True)\n",
    "  xgboost_scores_binary.append(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva-se os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump([ada_boost_scores_binary], open(\"../data/files/results/ada_boost_scores_binary.pkl\", \"wb\"))\n",
    "pkl.dump([random_forest_scores_binary], open(\"../data/files/results/random_forest_scores_binary.pkl\", \"wb\"))\n",
    "pkl.dump([bagging_scores_binary], open(\"../data/files/results/bagging_scores_binary.pkl\", \"wb\"))\n",
    "pkl.dump([mlp_scores_binary], open(\"../data/files/results/mlp_scores_binary.pkl\", \"wb\"))\n",
    "pkl.dump([xgboost_scores_binary], open(\"../data/files/results/xgboost_scores_binary.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos Adaptive Boosting, Random Forest, Bagging, Extreme Gradient Boosting e Multilayer Perceptron em validação cruzada | Classificação multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier(random_state = 42, algorithm = \"SAMME\", n_estimators = 400, learning_rate = 1.5)\n",
    "random_forest = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = 2)\n",
    "bagging = BaggingClassifier(random_state = 42, n_estimators = 100, max_features = 1, max_samples = 0.3, n_jobs = 2)\n",
    "mlp = MLPClassifier(random_state = 42, activation = \"tanh\", hidden_layer_sizes = (100, 100, 100))\n",
    "xgboost = xgb.XGBClassifier(random_state = 42, n_estimators = 400, max_depth = 5, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "\n",
      "Random Forest\n",
      "\n",
      "Bagging\n",
      "\n",
      "MLP\n",
      "\n",
      "XGBoost\n",
      "AdaBoost\n",
      "\n",
      "Random Forest\n",
      "\n",
      "Bagging\n",
      "\n",
      "MLP\n",
      "\n",
      "XGBoost\n",
      "AdaBoost\n",
      "\n",
      "Random Forest\n",
      "\n",
      "Bagging\n",
      "\n",
      "MLP\n",
      "\n",
      "XGBoost\n",
      "AdaBoost\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[i], y\u001b[38;5;241m.\u001b[39miloc[j]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdaBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m model_scores \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mada_boost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattack_cat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattack_cat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m ada_boost_scores_multiclass\u001b[38;5;241m.\u001b[39mappend(model_scores)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(model, X_train, X_test, y_train, y_test, scores, hierarchical)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_model\u001b[39m(model, X_train, X_test, y_train, y_test, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, hierarchical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m   \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m   y_predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m scores:\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:169\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    166\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:589\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_discrete\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:656\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_discrete\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME discrete algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    654\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 656\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ada_boost_scores_multiclass = []; random_forest_scores_multiclass = []; bagging_scores_multiclass = []; mlp_scores_multiclass = []; xgboost_scores_multiclass = []\n",
    "\n",
    "for i, j in k_folds.split(X):\n",
    "  \n",
    "  X_train, X_test = X.iloc[i], X.iloc[j]\n",
    "  y_train, y_test = y.iloc[i], y.iloc[j]\n",
    "\n",
    "\n",
    "  print(\"AdaBoost\")\n",
    "  model_scores = run_model(ada_boost, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"], scores = True)\n",
    "  ada_boost_scores_multiclass.append(model_scores)\n",
    "  print(\"\\nRandom Forest\")\n",
    "  model_scores = run_model(random_forest, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"], scores = True)\n",
    "  random_forest_scores_multiclass.append(model_scores)\n",
    "  print(\"\\nBagging\")\n",
    "  model_scores = run_model(bagging, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"], scores = True)\n",
    "  bagging_scores_multiclass.append(model_scores)\n",
    "  print(\"\\nMLP\")\n",
    "  model_scores = run_model(mlp, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"], scores = True)\n",
    "  mlp_scores_multiclass.append(model_scores)\n",
    "  print(\"\\nXGBoost\")\n",
    "  model_scores = run_model(xgboost, X_train, X_test, y_train[\"attack_cat\"], y_test[\"attack_cat\"], scores = True)\n",
    "  xgboost_scores_multiclass.append(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva-se os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump([ada_boost_scores_multiclass], open(\"../data/files/results/ada_boost_scores_multiclass_.pkl\", \"wb\"))\n",
    "pkl.dump([random_forest_scores_multiclass], open(\"../data/files/results/random_forest_scores_multiclass_.pkl\", \"wb\"))\n",
    "pkl.dump([bagging_scores_multiclass], open(\"../data/files/results/bagging_scores_multiclass_.pkl\", \"wb\"))\n",
    "pkl.dump([mlp_scores_multiclass], open(\"../data/files/results/mlp_scores_multiclass_.pkl\", \"wb\"))\n",
    "pkl.dump([xgboost_scores_multiclass], open(\"../data/files/results/xgboost_scores_multiclass_.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos: Classificador Local por Nó, Classificador Local por Nó Pai e Classificador Local por Nível em validação cruzada | Classificação Hierárquica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_classifier_per_node_base_estimator = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = 2)\n",
    "local_classifier_per_parent_node_base_estimator = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = 2)\n",
    "local_classifier_per_level_base_estimator = RandomForestClassifier(random_state = 42, n_estimators = 400, n_jobs = 2)\n",
    "\n",
    "local_classifier_per_node = LocalClassifierPerNode(local_classifier_per_node_base_estimator)\n",
    "local_classifier_per_parent_node = LocalClassifierPerParentNode(local_classifier_per_parent_node_base_estimator)\n",
    "local_classifier_per_level = LocalClassifierPerLevel(local_classifier_per_level_base_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Classifier Per Node\n",
      "\n",
      "Local Classifier Per Parent Node\n",
      "\n",
      "Local Classifier Per Level\n",
      "Local Classifier Per Node\n",
      "\n",
      "Local Classifier Per Parent Node\n",
      "\n",
      "Local Classifier Per Level\n",
      "Local Classifier Per Node\n",
      "\n",
      "Local Classifier Per Parent Node\n",
      "\n",
      "Local Classifier Per Level\n",
      "Local Classifier Per Node\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[i], y\u001b[38;5;241m.\u001b[39miloc[j]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocal Classifier Per Node\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m model_scores \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_classifier_per_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattack_cat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattack_cat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhierarchical\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m local_classifier_per_node_scores\u001b[38;5;241m.\u001b[39mappend(model_scores)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLocal Classifier Per Parent Node\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(model, X_train, X_test, y_train, y_test, scores, hierarchical)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_model\u001b[39m(model, X_train, X_test, y_train, y_test, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, hierarchical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m   \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m   y_predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m scores:\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\hiclass\\LocalClassifierPerNode.py:129\u001b[0m, in \u001b[0;36mLocalClassifierPerNode.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_binary_policy()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Fit local classifiers in DAG\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# TODO: Store the classes seen during fit\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# TODO: Add function to allow user to change local classifier\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Return the classifier\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\hiclass\\HierarchicalClassifier.py:136\u001b[0m, in \u001b[0;36mHierarchicalClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03mFit a local hierarchical classifier.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Fit local classifiers in DAG\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_digraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Delete unnecessary variables\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_up()\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\hiclass\\LocalClassifierPerNode.py:243\u001b[0m, in \u001b[0;36mLocalClassifierPerNode._fit_digraph\u001b[1;34m(self, local_mode, use_joblib)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# Remove root because it does not need to be fitted\u001b[39;00m\n\u001b[0;32m    242\u001b[0m nodes\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_)\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_node_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_joblib\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\hiclass\\HierarchicalClassifier.py:345\u001b[0m, in \u001b[0;36mHierarchicalClassifier._fit_node_classifier\u001b[1;34m(self, nodes, local_mode, use_joblib)\u001b[0m\n\u001b[0;32m    340\u001b[0m         classifiers \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    341\u001b[0m             delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_classifier)(\u001b[38;5;28mself\u001b[39m, node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[0;32m    342\u001b[0m         )\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m     classifiers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classifier, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classifiers, nodes):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhierarchy_\u001b[38;5;241m.\u001b[39mnodes[node][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m classifier\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\hiclass\\HierarchicalClassifier.py:345\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    340\u001b[0m         classifiers \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    341\u001b[0m             delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_classifier)(\u001b[38;5;28mself\u001b[39m, node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[0;32m    342\u001b[0m         )\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m     classifiers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classifier, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classifiers, nodes):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhierarchy_\u001b[38;5;241m.\u001b[39mnodes[node][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m classifier\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\hiclass\\LocalClassifierPerNode.py:264\u001b[0m, in \u001b[0;36mLocalClassifierPerNode._fit_classifier\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m         \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m         classifier\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rober\\programming\\artificial_intelligence\\ai_class\\data\\utilities\\anomaly_detection_venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "local_classifier_per_node_scores = []; local_classifier_per_parent_node_scores = []; local_classifier_per_level_scores = []\n",
    "# local_classifier_per_node_confusion_matrix_binary = []; local_classifier_per_parent_node_confusion_matrix_binary = []; local_classifier_per_level_confusion_matrix_binary = []\n",
    "# local_classifier_per_node_confusion_matrix_multiclass = []; local_classifier_per_parent_node_confusion_matrix_multiclass = []; local_classifier_per_level_confusion_matrix_multiclass = []\n",
    "\n",
    "\n",
    "for i, j in k_folds.split(X):\n",
    "\n",
    "  X_train, X_test = X.iloc[i], X.iloc[j]\n",
    "  y_train, y_test = y.iloc[i], y.iloc[j]\n",
    "\n",
    "  print(\"Local Classifier Per Node\")\n",
    "  model_scores = run_model(local_classifier_per_node, X_train, X_test, y_train[[\"Label\", \"attack_cat\"]], y_test[[\"Label\", \"attack_cat\"]], scores = True, hierarchical = True)\n",
    "  local_classifier_per_node_scores.append(model_scores)\n",
    "  print(\"\\nLocal Classifier Per Parent Node\")\n",
    "  model_scores = run_model(local_classifier_per_parent_node, X_train, X_test, y_train[[\"Label\", \"attack_cat\"]], y_test[[\"Label\", \"attack_cat\"]], scores = True, hierarchical = True)\n",
    "  local_classifier_per_parent_node_scores.append(model_scores)\n",
    "  print(\"\\nLocal Classifier Per Level\")\n",
    "  model_scores = run_model(local_classifier_per_level, X_train, X_test, y_train[[\"Label\", \"attack_cat\"]], y_test[[\"Label\", \"attack_cat\"]], scores = True, hierarchical = True)\n",
    "  local_classifier_per_level_scores.append(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salve-se os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump([local_classifier_per_node_scores], open(\"../data/files/results/local_classifier_per_node_scores_.pkl\", \"wb\"))\n",
    "pkl.dump([local_classifier_per_parent_node_scores], open(\"../data/files/results/local_classifier_per_parent_node_scores_.pkl\", \"wb\"))\n",
    "pkl.dump([local_classifier_per_level_scores], open(\"../data/files/results/local_classifier_per_level_scores_.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
