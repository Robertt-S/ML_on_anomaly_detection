{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de utilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train, X_test, y_train, y_test, verbose = False, scores = False):\n",
    "  model.fit(X_train, y_train)\n",
    "  y_predicted = model.predict(X_test)\n",
    "\n",
    "  train_accuracy = model.score(X_train, y_train)\n",
    "  test_accuracy = accuracy_score(y_test, y_predicted)\n",
    "  test_balanced_accuracy = balanced_accuracy_score(y_test, y_predicted)\n",
    "\n",
    "  if verbose:\n",
    "    print(f\"Acurácia no treino {train_accuracy} \\nAcurácia no teste: {test_accuracy} \\nAcurácia balanceada no teste: {test_balanced_accuracy}\")\n",
    "\n",
    "  if scores:\n",
    "    return (pd.DataFrame({\"Acurácia no Treino\": train_accuracy,\n",
    "                         \"Acurácia no Teste\": test_accuracy, \n",
    "                         \"Acurácia Balanceada no Teste\": test_balanced_accuracy,\n",
    "                         \"Precisão\": classification_report(y_test, y_predicted, output_dict = True)[\"1\"][\"precision\"],\n",
    "                         \"Recall\": classification_report(y_test, y_predicted, output_dict = True)[\"1\"][\"recall\"],\n",
    "                         \"F1\": classification_report(y_test, y_predicted, output_dict = True)[\"1\"][\"f1-score\"]}), \n",
    "                         confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega-se os dados pré-processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pkl.load(open(\"../data/files/Normalized_Data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = [\"attack_cat\", \"Label\"])\n",
    "y = df[[\"attack_cat\", \"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y[[\"Label\", \"attack_cat\"]], test_size = 0.2, stratify = y, random_state = 42)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação da base em K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = KFold(n_splits = 10, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção das características mais importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[\"dstip\", \"ct_state_ttl\", \"sttl\", \"srcip\", \"sbytes\"]]\n",
    "X_test = X_test[[\"dstip\", \"ct_state_ttl\", \"sttl\", \"srcip\", \"sbytes\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos | Classificação binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier(random_state = 42, algorithm = \"SAMME\", n_estimators = 200, learning_rate = 1)\n",
    "random_forest = RandomForestClassifier(random_state = 42, n_estimators = 200, max_depth = 10, min_samples_split = 10)\n",
    "bagging = BaggingClassifier(random_state = 42)\n",
    "stacking = StackingClassifier(random_state = 42)\n",
    "mlp = MLPClassifier(random_state = 42)\n",
    "xgboost = xgb.XGBClassifier(random_state = 42, n_estimators = 200, max_depth = 10, learning_rate = 1, min_samples_split = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_scores = pd.DataFrame(), random_forest_scores = pd.DataFrame(), bagging_scores = pd.DataFrame(), stacking_scores = pd.DataFrame(), mlp_scores = pd.DataFrame(), xgboost_scores = pd.DataFrame()\n",
    "ada_boost_confusion_matrix = None, random_forest_confusion_matrix = None, bagging_confusion_matrix = None, stacking_confusion_matrix = None, mlp_confusion_matrix = None, xgboost_confusion_matrix = None\n",
    "\n",
    "\n",
    "for i, j in k_folds.split(X):\n",
    "  X_train, X_test = X.iloc[i], X.iloc[j]\n",
    "  y_train, y_test = y.iloc[i], y.iloc[j]\n",
    "\n",
    "\n",
    "  print(\"AdaBoost\")\n",
    "  model_scores, model_confusion_matrix = run_model(ada_boost, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], verbose = True, scores = True)\n",
    "  ada_boost_scores = pd.concat([ada_boost_scores, model_scores])\n",
    "  ada_boost_confusion_matrix.append(model_confusion_matrix)\n",
    "  print(\"\\nRandom Forest\")\n",
    "  model_scores, model_confusion_matrix = run_model(random_forest, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], verbose = True, scores = True)\n",
    "  random_forest_scores = pd.concat([random_forest_scores, model_scores])\n",
    "  random_forest_confusion_matrix.append(model_confusion_matrix)\n",
    "  print(\"\\nBagging\")\n",
    "  model_scores, model_confusion_matrix = run_model(bagging, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], verbose = True, scores = True)\n",
    "  bagging_scores = pd.concat([bagging_scores, model_scores])\n",
    "  bagging_confusion_matrix.append(model_confusion_matrix)\n",
    "  print(\"\\nStacking\")\n",
    "  model_scores, model_confusion_matrix = run_model(stacking, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], verbose = True, scores = True)\n",
    "  stacking_scores = pd.concat([stacking_scores, model_scores])\n",
    "  stacking_confusion_matrix.append(model_confusion_matrix)\n",
    "  print(\"\\nMLP\")\n",
    "  model_scores, model_confusion_matrix = run_model(mlp, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], verbose = True, scores = True)\n",
    "  mlp_scores = pd.concat([mlp_scores, model_scores])\n",
    "  mlp_confusion_matrix.append(model_confusion_matrix)\n",
    "  print(\"\\nXGBoost\")\n",
    "  model_scores, model_confusion_matrix = run_model(xgboost, X_train, X_test, y_train[\"Label\"], y_test[\"Label\"], verbose = True, scores = True)\n",
    "  xgboost_scores = pd.concat([xgboost_scores, model_scores])\n",
    "  xgboost_confusion_matrix.append(model_confusion_matrix)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução dos modelos | Classificação multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
